2025-11-13 10:22:30   --- Hyperparameters ---
2025-11-13 10:22:30   model = DenseMsaNet(
2025-11-13 10:22:30     (dense_layer1): Sequential(
2025-11-13 10:22:30       (0): Linear(in_features=22, out_features=100, bias=True)
2025-11-13 10:22:30       (1): ReLU()
2025-11-13 10:22:30       (2): Dropout(p=0.2, inplace=False)
2025-11-13 10:22:30     )
2025-11-13 10:22:30     (dense_layer2): Linear(in_features=100, out_features=1, bias=True)
2025-11-13 10:22:30   )
2025-11-13 10:22:30   split_proportion = 0.9
2025-11-13 10:22:30   batch_pad_sequences = False
2025-11-13 10:22:30   learning_rate = 0.01
2025-11-13 10:22:30   batch_size = 64
2025-11-13 10:22:30   max_epochs = 500
2025-11-13 10:22:30   early_stopping_patience = 20
2025-11-13 10:22:30   --- Creating loaders ---
2025-11-13 10:22:32   --- Training start ---
2025-11-13 10:22:32   Start training using cpu device.
2025-11-13 10:22:32   Number of model parameters: 2401.
2025-11-13 10:22:32   Epoch   Train loss   Valid loss   Valid acc    F1-score        Lr   Best
2025-11-13 10:22:32   ------------------------------------------------------------------------
2025-11-13 10:22:32       1        0.693        0.694       0.471       0.000   0.00000      *
2025-11-13 10:22:32       2        0.693        0.694       0.471       0.000   0.00250       
2025-11-13 10:22:33       3        0.693        0.692       0.471       0.000   0.00500      *
2025-11-13 10:22:33       4        0.693        0.694       0.465       0.080   0.00750       
2025-11-13 10:22:33       5        0.695        0.692       0.471       0.000   0.01000      *
2025-11-13 10:22:33       6        0.693        0.694       0.413       0.436   0.00990       
2025-11-13 10:22:33       7        0.693        0.694       0.483       0.643   0.00980       
2025-11-13 10:22:33       8        0.693        0.696       0.442       0.020   0.00970       
2025-11-13 10:22:33       9        0.693        0.696       0.459       0.000   0.00961       
2025-11-13 10:22:34      10        0.692        0.695       0.459       0.079   0.00951       
2025-11-13 10:22:34      11        0.693        0.697       0.459       0.000   0.00941       
2025-11-13 10:22:34      12        0.693        0.694       0.488       0.639   0.00932       
2025-11-13 10:22:34      13        0.692        0.695       0.459       0.097   0.00923       
2025-11-13 10:22:34      14        0.692        0.695       0.453       0.591   0.00914       
2025-11-13 10:22:34      15        0.692        0.695       0.471       0.133   0.00904       
2025-11-13 10:22:34      16        0.692        0.695       0.401       0.352   0.00895       
2025-11-13 10:22:35      17        0.692        0.695       0.465       0.403   0.00886       
2025-11-13 10:22:35      18        0.692        0.696       0.448       0.228   0.00878       
2025-11-13 10:22:35      19        0.692        0.697       0.390       0.393   0.00869       
2025-11-13 10:22:35      20        0.692        0.698       0.459       0.079   0.00860       
2025-11-13 10:22:35      21        0.691        0.697       0.453       0.373   0.00851       
2025-11-13 10:22:35      22        0.691        0.700       0.459       0.097   0.00843       
2025-11-13 10:22:35      23        0.691        0.698       0.459       0.268   0.00835       
2025-11-13 10:22:36      24        0.691        0.698       0.477       0.318   0.00826       
2025-11-13 10:22:36      25        0.690        0.698       0.488       0.302   0.00818       
2025-11-13 10:22:36   --- Training ended ---
2025-11-13 10:22:36   Number of model parameters: 2401
2025-11-13 10:22:36   Training time: 0:00:04
2025-11-13 10:22:36   Best epoch: 5
2025-11-13 10:22:36   Best valid loss: 0.692
2025-11-13 10:22:36   Best valid accuracy (macro): 0.471
2025-11-13 10:22:36   Best F1 score: 0.000
