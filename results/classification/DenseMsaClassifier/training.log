2025-11-07 17:40:12   --- Hyperparameters ---
2025-11-07 17:40:12   model = DenseMsaNet(
2025-11-07 17:40:12     (dense_layer1): Sequential(
2025-11-07 17:40:12       (0): Linear(in_features=22, out_features=100, bias=True)
2025-11-07 17:40:12       (1): ReLU()
2025-11-07 17:40:12       (2): Dropout(p=0.2, inplace=False)
2025-11-07 17:40:12     )
2025-11-07 17:40:12     (dense_layer2): Linear(in_features=100, out_features=1, bias=True)
2025-11-07 17:40:12   )
2025-11-07 17:40:12   split_proportion = 0.9
2025-11-07 17:40:12   batch_pad_sequences = False
2025-11-07 17:40:12   learning_rate = 0.01
2025-11-07 17:40:12   batch_size = 64
2025-11-07 17:40:12   max_epochs = 500
2025-11-07 17:40:12   early_stopping_patience = 20
2025-11-07 17:40:12   --- Creating loaders ---
2025-11-07 17:40:13   --- Training start ---
2025-11-07 17:40:13   Start training using cpu device.
2025-11-07 17:40:13   Number of model parameters: 2401.
2025-11-07 17:40:13   Epoch   Train loss   Valid loss   Valid acc    F1-score        Lr   Best
2025-11-07 17:40:13   ------------------------------------------------------------------------
2025-11-07 17:40:13       1        0.693        0.695       0.471       0.000   0.00000      *
2025-11-07 17:40:13       2        0.693        0.693       0.506       0.220   0.00250      *
2025-11-07 17:40:13       3        0.693        0.692       0.471       0.000   0.00500      *
2025-11-07 17:40:13       4        0.693        0.696       0.471       0.000   0.00750       
2025-11-07 17:40:13       5        0.693        0.694       0.471       0.000   0.01000       
2025-11-07 17:40:13       6        0.694        0.692       0.471       0.000   0.00990      *
2025-11-07 17:40:14       7        0.693        0.695       0.471       0.000   0.00980       
2025-11-07 17:40:14       8        0.693        0.694       0.471       0.000   0.00970       
2025-11-07 17:40:14       9        0.693        0.693       0.488       0.200   0.00961       
2025-11-07 17:40:14      10        0.693        0.694       0.471       0.000   0.00951       
2025-11-07 17:40:14      11        0.693        0.693       0.471       0.000   0.00941       
2025-11-07 17:40:14      12        0.693        0.693       0.535       0.273   0.00932       
2025-11-07 17:40:14      13        0.693        0.693       0.517       0.677   0.00923       
2025-11-07 17:40:14      14        0.693        0.693       0.483       0.360   0.00914       
2025-11-07 17:40:14      15        0.693        0.694       0.471       0.000   0.00904       
2025-11-07 17:40:14      16        0.693        0.693       0.494       0.315   0.00895       
2025-11-07 17:40:14      17        0.693        0.694       0.529       0.308   0.00886       
2025-11-07 17:40:15      18        0.693        0.693       0.494       0.567   0.00878       
2025-11-07 17:40:15      19        0.693        0.694       0.483       0.063   0.00869       
2025-11-07 17:40:15      20        0.693        0.694       0.471       0.000   0.00860       
2025-11-07 17:40:15      21        0.693        0.693       0.506       0.124   0.00851       
2025-11-07 17:40:15      22        0.693        0.693       0.535       0.518   0.00843       
2025-11-07 17:40:15      23        0.692        0.693       0.512       0.408   0.00835       
2025-11-07 17:40:15      24        0.692        0.694       0.483       0.152   0.00826       
2025-11-07 17:40:15      25        0.693        0.693       0.465       0.623   0.00818       
2025-11-07 17:40:15      26        0.692        0.694       0.483       0.063   0.00810       
2025-11-07 17:40:15   --- Training ended ---
2025-11-07 17:40:15   Number of model parameters: 2401
2025-11-07 17:40:15   Training time: 0:00:03
2025-11-07 17:40:15   Best epoch: 6
2025-11-07 17:40:15   Best valid loss: 0.692
2025-11-07 17:40:15   Best valid accuracy (macro): 0.471
2025-11-07 17:40:15   Best F1 score: 0.000
