# üîÑ Garanties de R√©initialisation pour RUN 2

## üìã R√©sum√©

RUN 2 est **compl√®tement r√©initialis√©** et ne conserve **AUCUN √©tat** de RUN 1. Seule l'architecture du meilleur mod√®le de RUN 1 est r√©utilis√©e, mais avec des **poids compl√®tement nouveaux**.

---

## ‚úÖ Ce qui EST r√©initialis√© (pas de cache)

### 1. **Mod√®le Neural Network**
```python
# NOUVEAU mod√®le cr√©√© √† chaque fois
model = clf["classifier_fn"](**args)  # Ligne 231 de pipeline.py
```
- ‚úÖ **Nouvelle instance** du mod√®le cr√©√©e
- ‚úÖ **Poids al√©atoires** (initialization from scratch)
- ‚úÖ **Pas de transfert de poids** depuis RUN 1
- ‚úÖ Seeds contr√¥l√©s par `RANDOM_SEED = 42` pour reproductibilit√©

### 2. **Optimizer & Scheduler**
- ‚úÖ **Nouvel optimizer** cr√©√© dans `Training.__init__()`
- ‚úÖ **Nouveau learning rate scheduler** cr√©√©
- ‚úÖ **Pas d'√©tat d'optimizer** conserv√©

### 3. **Fichiers & Checkpoints**
```python
# Suppression explicite avant RUN 2
existing_model.unlink()              # Supprime best_model.pt
shutil.rmtree(checkpoint_dir)        # Supprime tout le dossier checkpoint/
```
- ‚úÖ `best_model.pt` supprim√©
- ‚úÖ Tout le dossier `checkpoint/` supprim√©
- ‚úÖ Pas de fichiers r√©siduels

### 4. **M√©moire GPU/CPU**
```python
torch.cuda.empty_cache()  # Vide le cache CUDA si GPU
gc.collect()              # Force garbage collection Python
```
- ‚úÖ Cache CUDA vid√© (si GPU utilis√©)
- ‚úÖ Garbage collection forc√©e
- ‚úÖ M√©moire lib√©r√©e

### 5. **Dataset**
```python
self.base_data = Data(
    source_real=FastaSource(self.out_path / "run_2_real"),
    source_simulated=FastaSource(self.out_path / "run_2_sim"),
    tokenizer=self.tokenizer,
)
```
- ‚úÖ **Nouveau dataset** charg√©
- ‚úÖ Fichiers diff√©rents (run_2_real, run_2_sim)
- ‚úÖ Nouvelles donn√©es tokenis√©es

---

## üîç Ce qui est CONSERV√â (intentionnel)

### 1. **Architecture du mod√®le**
- Le **type** de mod√®le (ex: AACnnClassifier)
- L'**architecture** (nombre de couches, taille)
- Les **hyperparam√®tres** (learning rate, batch size, etc.)

**Pourquoi ?** C'est le but de RUN 2 : r√©entra√Æner le meilleur mod√®le avec de meilleures donn√©es.

### 2. **Seeds al√©atoires**
- `RANDOM_SEED = 42` reste identique

**Pourquoi ?** Pour la **reproductibilit√©** des exp√©riences.

### 3. **Configuration du pipeline**
- Param√®tres globaux (device, paths, etc.)

---

## üî¨ V√©rification du Comportement

### Test 1: Nouveau mod√®le cr√©√©
```python
# Dans train_classifier():
model = clf["classifier_fn"](**args)  # <-- NOUVELLE instance
# Chaque appel cr√©e un objet Python diff√©rent
```

### Test 2: Poids r√©initialis√©s
Les poids sont initialis√©s selon la strat√©gie du mod√®le :
- **PyTorch default**: Xavier/Kaiming initialization
- **Al√©atoire** bas√© sur les seeds

### Test 3: Pas de gradient flow
- Pas de `.requires_grad` conserv√©
- Pas d'historique de backprop
- Nouveau graphe de computation

### Test 4: Checkpoints propres
```bash
# Avant RUN 2:
results/classification/run_2/AACnnClassifier/
‚îî‚îÄ‚îÄ (vide ou ancien supprim√©)

# Apr√®s nettoyage:
results/classification/run_2/AACnnClassifier/
‚îî‚îÄ‚îÄ (compl√®tement vide)

# Apr√®s RUN 2:
results/classification/run_2/AACnnClassifier/
‚îú‚îÄ‚îÄ best_model.pt          (NOUVEAU)
‚îú‚îÄ‚îÄ checkpoint/
‚îÇ   ‚îî‚îÄ‚îÄ best_*.pt          (NOUVEAUX)
‚îî‚îÄ‚îÄ train_history.parquet  (NOUVEAU)
```

---

## üìä Logs de Confirmation

Lors de l'ex√©cution, vous verrez :

```
[RUN 2] Retraining AACnnClassifier with Run 2 dataset...
[RUN 2] Removed existing best_model.pt
[RUN 2] Removed checkpoint directory
[RUN 2] Cleared CUDA cache
[RUN 2] Starting fresh training (new model instance, no weights from RUN 1)
[RUN] Training AACnnClassifier
--- Hyperparameters ---
model = AAConvNet(...)  # <-- Nouvelle instance
...
--- Training start ---
Start training using cpu device.
Number of model parameters: 1537.
```

---

## üéØ Conclusion

### ‚úÖ Garanties fournies :

1. **Mod√®le**: Nouveau mod√®le avec poids al√©atoires
2. **Optimizer**: Nouvel optimizer/scheduler
3. **Fichiers**: Tous les fichiers pr√©c√©dents supprim√©s
4. **M√©moire**: Cache CUDA vid√©, GC forc√©
5. **Dataset**: Nouvelles donn√©es charg√©es

### ‚ùå Pas de risque de :

- ‚ùå Transfert de poids entre RUN 1 et RUN 2
- ‚ùå √âtat d'optimizer conserv√©
- ‚ùå M√©moire GPU r√©siduelle
- ‚ùå Fichiers de checkpoint m√©lang√©s
- ‚ùå Overfitting sur les m√™mes initialisations

### üîí Reproductibilit√© :

- Seeds contr√¥l√©s (`RANDOM_SEED = 42`)
- M√™me comportement √† chaque ex√©cution
- R√©sultats comparables entre runs

---

## üìù Code Modifi√©

**Fichier**: `backup/simulations-classifiers/src/classifiers/pipeline.py`

**M√©thode**: `run2_retrain_best_model()` (lignes ~1118-1133)

**Modifications**:
1. ‚úÖ Import `gc` ajout√©
2. ‚úÖ Suppression de `best_model.pt`
3. ‚úÖ Suppression du dossier `checkpoint/`
4. ‚úÖ Vidage du cache CUDA
5. ‚úÖ Garbage collection forc√©e
6. ‚úÖ Logs informatifs

---

**Date**: 2025-12-02  
**Auteur**: Assistant IA avec Lorcan

