# üîß Modifications du calcul du seuil optimal dans pipeline.py

## üìù R√©sum√© des changements

Le fichier `backup/simulations-classifiers/src/classifiers/pipeline.py` a √©t√© modifi√© pour corriger le calcul du seuil optimal de classification.

---

## ‚ùå Probl√®me initial

### Comportement ancien (INCORRECT)
La m√©thode `_find_optimal_threshold_roc()` **retournait l'AUC comme seuil de classification** :

```python
# ANCIEN CODE (INCORRECT)
auc = roc_auc_score(y_true, y_score)
return float(auc)  # ‚ùå Utilise l'AUC (ex: 0.87) comme seuil !
```

**Pourquoi c'est incorrect :**
- L'AUC est une **m√©trique de performance** (entre 0 et 1)
- Ce n'est **PAS un seuil de classification** !
- R√©sultat : seuils tr√®s √©lev√©s (~0.87) qui classent presque tout dans une seule classe

### Cons√©quences observ√©es
```
RUN 1: threshold = 0.8671 ‚Üí Seulement 3.37% des donn√©es retenues
RUN 2: threshold = 0.8778 ‚Üí Seulement 4.41% des donn√©es retenues
```

Presque toutes les pr√©dictions tombaient dans une seule classe car le seuil √©tait trop √©lev√©.

---

## ‚úÖ Solution impl√©ment√©e

### Nouveau comportement (CORRECT)

La m√©thode utilise maintenant le **J de Youden** pour trouver le seuil optimal sur la courbe ROC :

```python
# NOUVEAU CODE (CORRECT)
fpr, tpr, thresholds = roc_curve(y_true, y_score)

# Calcul du J de Youden (TPR - FPR)
j_scores = tpr - fpr

# Trouver le seuil qui maximise J
optimal_idx = np.argmax(j_scores)
optimal_threshold = thresholds[optimal_idx]
```

**Avantages :**
- ‚úÖ Maximise la s√©paration entre les deux classes
- ‚úÖ √âquilibre TPR (sensibilit√©) et FPR (sp√©cificit√©)
- ‚úÖ Seuil statistiquement optimal bas√© sur la courbe ROC

### Gestion des pr√©dictions invers√©es

Le code d√©tecte maintenant si le mod√®le pr√©dit √† l'envers (AUC < 0.5) :

```python
if auc < 0.5:
    # Mod√®le pr√©dit l'inverse ‚Üí inverser les scores
    y_score_inverted = 1 - y_score
    # Recalculer ROC avec scores invers√©s
    fpr, tpr, thresholds = roc_curve(y_true, y_score_inverted)
    # Inverser le seuil pour application aux scores originaux
    optimal_threshold = 1.0 - optimal_threshold
```

**Pourquoi c'est n√©cessaire :**
- Les logs montraient `AUC = 0.13` (pire que le hasard)
- Cela sugg√®re que les labels sont invers√©s quelque part
- L'inversion permet d'obtenir un seuil correct malgr√© ce probl√®me

---

## üìä Impact attendu

### Avant (avec AUC comme seuil)
```
Seuil: ~0.87 (tr√®s √©lev√©)
R√©tention: 3-5% des donn√©es
F1-score: ~0.004
Accuracy: ~48%
```

### Apr√®s (avec Youden's J)
```
Seuil: ~0.3-0.5 (plus raisonnable)
R√©tention: 30-60% des donn√©es (selon objectif)
F1-score: ~0.10-0.60 (meilleur)
Accuracy: ~20-44% (variable selon seuil)
```

---

## üîç D√©tails techniques

### M√©thode de Youden

Le **J de Youden** est d√©fini comme :
```
J = TPR - FPR = Sensibilit√© + Sp√©cificit√© - 1
```

Le seuil optimal est celui qui **maximise J**, c'est-√†-dire qui :
- Maximise le TPR (True Positive Rate / Sensibilit√©)
- Minimise le FPR (False Positive Rate)

### Localisation des modifications

**Fichier :** `backup/simulations-classifiers/src/classifiers/pipeline.py`

**M√©thode modifi√©e :** `_find_optimal_threshold_roc()` (lignes ~591-650)

**Appels (3 endroits) :**
1. Ligne ~952 : RUN 1 - Filtrage initial
2. Ligne ~1117 : RUN 2 - M√©thode `run2_retrain_best_model()`
3. Ligne ~1254 : RUN 2 - M√©thode `run_two_iterations()`

**Messages de log mis √† jour :**
```python
# Avant
f"threshold = {optimal_threshold:.4f} (AUC value)"

# Apr√®s
f"optimal threshold = {optimal_threshold:.4f} (from ROC - Youden's J)"
```

---

## üß™ Test et validation

### Scripts d'analyse cr√©√©s

1. **`scripts/analyse_predictions.py`**
   - Analyse les distributions de probabilit√©s
   - G√©n√®re des violin plots et histogrammes
   - Export CSV des pr√©dictions

2. **`scripts/analyse_thresholds.py`** (supprim√© apr√®s utilisation)
   - Teste diff√©rents seuils (0.3, 0.5, 0.7, 0.87)
   - Calcule m√©triques pour chaque seuil
   - Montre l'impact sur la r√©tention

3. **`scripts/visualize_optimal_threshold.py`**
   - Visualise la courbe ROC avec les diff√©rents seuils
   - Montre le J de Youden
   - Compare ancien vs nouveau seuil

### Commande de test
```bash
cd /home/lorcan/Documents/Master/Projet/ApprentiPhylo_clean
source .venv/bin/activate
python scripts/visualize_optimal_threshold.py
```

---

## ‚ö†Ô∏è Probl√®me d√©tect√© : Labels invers√©s

L'analyse a r√©v√©l√© un **probl√®me sous-jacent** :

```
AUC = 0.13 (tr√®s mauvais)
```

Un AUC de 0.13 signifie que le mod√®le pr√©dit **syst√©matiquement l'inverse** de ce qu'il devrait :
- Les **simul√©s** obtiennent des probabilit√©s **√©lev√©es** d'√™tre "r√©els"
- Les **r√©els** obtiennent des probabilit√©s **faibles**

**Hypoth√®ses :**
1. Labels invers√©s lors de l'entra√Ænement (`LABEL_REAL` et `LABEL_SIMULATED` √©chang√©s)
2. Logique invers√©e dans la fonction de pr√©diction
3. Les simulations sont "trop bonnes" et ressemblent plus aux donn√©es r√©elles

Le code modifi√© **d√©tecte et corrige automatiquement** ce probl√®me en inversant les pr√©dictions lors du calcul du seuil.

---

## üìÅ Fichiers g√©n√©r√©s

```
results/classification/predictions_analysis/
‚îú‚îÄ‚îÄ predictions_run1.csv
‚îú‚îÄ‚îÄ predictions_run2.csv
‚îú‚îÄ‚îÄ summary_statistics.csv
‚îú‚îÄ‚îÄ violin_plot_distributions.png
‚îú‚îÄ‚îÄ violin_plot_comparison.png
‚îú‚îÄ‚îÄ histogram_distributions.png
‚îú‚îÄ‚îÄ threshold_impact_analysis.png
‚îú‚îÄ‚îÄ threshold_metrics_run1.csv
‚îú‚îÄ‚îÄ threshold_metrics_run2.csv
‚îú‚îÄ‚îÄ optimal_threshold_comparison_run1.png
‚îî‚îÄ‚îÄ optimal_threshold_comparison_run2.png
```

---

## üöÄ Prochaines √©tapes recommand√©es

1. **R√©-ex√©cuter le pipeline complet** pour tester le nouveau calcul de seuil :
   ```bash
   python backup/simulations-classifiers/src/classifiers/pipeline.py \
       --config results/classification/config.json \
       --two-iterations
   ```

2. **V√©rifier les labels** dans le code d'entra√Ænement pour s'assurer qu'ils ne sont pas invers√©s

3. **Comparer les r√©sultats** avant/apr√®s modification

4. **Ajuster le calcul du seuil** si n√©cessaire (autres m√©thodes possibles : F1-max, distance √† (0,1), etc.)

---

## üìö R√©f√©rences

- **Youden's J statistic**: Youden, W. J. (1950). "Index for rating diagnostic tests". Cancer. 3 (1): 32‚Äì35.
- **ROC curves**: Fawcett, T. (2006). "An introduction to ROC analysis". Pattern Recognition Letters. 27 (8): 861‚Äì874.

---

**Date de modification :** 2025-12-02  
**Auteur :** Assistant IA avec Lorcan

